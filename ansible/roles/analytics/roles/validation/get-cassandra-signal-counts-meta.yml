# Copyright 2018 Dematic, Corp.  # Licensed under the MIT Open Source License: https://opensource.org/licenses/MIT
# get final events processed between kafka and spark/yarn from the cassandra table
# 1. signal_validation_producer_final_count = signal_validation.spark_count
# 2. signal_validation_spark_final_count= signal_validation.spark_count

# ansible-playbook -i /dematic/gitlab/devops-config/ansible/roles/validation/inventory/devops-ss-aggregation \
#  get-cassandra-signal-counts-meta.yml --private-key /dematic/keys/google/gcp-devops -u devops


- name: "Get Cassandra signal_validation table  producer and driver counts"
  hosts: cassandra-validator
  run_once: true
  vars:
  tasks:
    # we have to explicitly include this var filew hen this file is further included top level from validation
    - include_vars: ../cassandra/group_vars/all
    - include_vars: "{{spark_driver_conf_file}}"
    - set_fact: spark_driver_target={{spark_drivers_dict[spark_driver_key]}}
    - debug: var=spark_driver_target

    # need to execute statements like
    # cqlsh host -u spark -p password -k regr_sxxx
    # --execute="SELECT spark_count from regr_customer.signal_validation where id='regr_CUMULATIVE_SIGNAL_METRICS' limit 1" | grep -Po '.* \K\d+\.*\d*'

    - include: ../cassandra/tasks/execute-cql-stmt-numeric-result.yml
      vars:
        cql_stmt: "{{spark_driver_target.validation.consumer_spark_signal_count_cql}}"
        cql_query_failure_value: "-1"

    - set_fact: spark_final_count="{{table_select_numeric_result}}"

    - debug: var=spark_final_count


- name: "Local store signal_validation_spark_final_count {{spark_final_count}} "
  hosts:  localhost
  tasks:
    - set_fact: consumer_spark_final_count="{{ hostvars[item]['spark_final_count'] }}"
      with_inventory_hostnames: cassandra-validator
    - debug: var=consumer_spark_final_count
  tags:
     - transfer_cassandra_counts_to_local_vars
